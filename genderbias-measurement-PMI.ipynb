{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navid/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.stats import ttest_rel\n",
    "import copy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import utils\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "\n",
    "from scipy.stats.stats import spearmanr\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_model_name = \"sg_dim300_min200_win5\"\n",
    "we_vector_size = 300\n",
    "we_model_dir = \"/share/home/navid/wordembeddings/word2vecgensim/wikipedia/wiki-english-20171001/%s\" % we_model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n"
     ]
    }
   ],
   "source": [
    "we_model = Word2Vec.load(we_model_dir+'/model.gensim')\n",
    "print ('loading done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "wordpairs_debiasing_direction = []\n",
    "with open('resources/wordpairs_direction.txt') as fr:\n",
    "    for l in fr:\n",
    "        wordpairs_debiasing_direction.append(l.strip().split(','))\n",
    "print (len(wordpairs_debiasing_direction))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    }
   ],
   "source": [
    "job_tuples=[]\n",
    "with open('resources/wordlist_occupations.txt') as fr:\n",
    "    for l in fr:\n",
    "        _tuple=l.strip('\\n').split(',')\n",
    "        if _tuple[0] in we_model.wv.vocab:\n",
    "            job_tuples.append(_tuple)\n",
    "print (len(job_tuples))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(vec1, vec2):\n",
    "    return 1 - scipy.spatial.distance.cosine(vec1, vec2)\n",
    "\n",
    "def meanCosine(vec, set_vecs):\n",
    "    return np.mean([Cosine(vec, _set_vec) for _set_vec in set_vecs])\n",
    "\n",
    "def NegDifNorm(vec1, vec2):\n",
    "    return -np.linalg.norm((vec1/np.linalg.norm(vec1)) - (vec2/np.linalg.norm(vec2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n"
     ]
    }
   ],
   "source": [
    "coomtx_dir = '/share/home/navid/wordembeddings/cooccurrencematrix/wikipedia/wiki-english-20171001/min200_win5'\n",
    "coomtx_dict = Dictionary.load(coomtx_dir + '/dictionary.gensim')\n",
    "_loader = np.load(coomtx_dir + '/cooccurrence_matrix.npz')\n",
    "coomtx = csr_matrix((_loader['data'], _loader['indices'], _loader['indptr']), shape = _loader['shape'])\n",
    "with open(coomtx_dir + '/vocabs_count.pkl', 'rb') as fr:\n",
    "    coomtx_vocabcount = pickle.load(fr)\n",
    "\n",
    "print ('loading done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "cds=0.75\n",
    "\n",
    "coomtx_colsum_vec = np.array(coomtx.sum(axis=0), dtype=np.float64)[0]\n",
    "coomtx_colsum_vec[coomtx_colsum_vec==0] = 1.0\n",
    "coomtx_colsum_cds_vec = coomtx_colsum_vec ** cds\n",
    "coomtx_colsum_cds_vec_sum = np.sum(coomtx_colsum_cds_vec)\n",
    "\n",
    "coomtx_D_cnt=float(coomtx.sum())\n",
    "print ('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading SVDs done!\n"
     ]
    }
   ],
   "source": [
    "with open(coomtx_dir + '/pmi_svd_matrix.pkl', 'rb') as fr:\n",
    "    pmisvd_matrix = pickle.load(fr)\n",
    "with open(coomtx_dir + '/ppmi_svd_matrix.pkl', 'rb') as fr:\n",
    "    ppmisvd_matrix = pickle.load(fr)\n",
    "with open(coomtx_dir + '/sppmi_svd_matrix.pkl', 'rb') as fr:\n",
    "    sppmisvd_matrix = pickle.load(fr)\n",
    "\n",
    "\n",
    "print ('loading SVDs done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navid/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'book': array([1.89892886e-02, 3.85159410e-06, 7.96881537e-07, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00])},\n",
       " {'book': array([ 1.35301275, -1.11489032, -0.26904235, ...,  0.        ,\n",
       "          0.        ,  0.        ])},\n",
       " {'book': array([1.35301275, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ])},\n",
       " {'book': array([0., 0., 0., ..., 0., 0., 0.])})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_cooccurrence_vec(word):\n",
    "    _idx = coomtx_dict.token2id[word]\n",
    "    _vec = np.array(coomtx.getrow(_idx).toarray()[0], dtype=np.float64)\n",
    "    return _vec\n",
    "\n",
    "def get_cooccurprob_vec(word):\n",
    "    _coo_vec = get_cooccurrence_vec(word)\n",
    "    _vec = _coo_vec / np.sum(_coo_vec)\n",
    "    return _vec\n",
    "\n",
    "\n",
    "def get_pmi_vec(word):\n",
    "    _coo_vec = get_cooccurrence_vec(word)\n",
    "    _vec = np.log((_coo_vec * coomtx_D_cnt) / (np.sum(_coo_vec) * coomtx_colsum_vec))\n",
    "    return _vec\n",
    "\n",
    "def get_pmicds_vec(word):\n",
    "    _coo_vec = get_cooccurrence_vec(word)\n",
    "    _vec = np.log((_coo_vec) / (np.sum(_coo_vec) * (coomtx_colsum_cds_vec / coomtx_colsum_cds_vec_sum)))\n",
    "    return _vec\n",
    "\n",
    "def get_pmibased_vecs(words):\n",
    "    ns=5.\n",
    "    \n",
    "    get_cooccurprob_vec\n",
    "    \n",
    "    CoProb_vecs = {}\n",
    "    PMI_vecs = {}\n",
    "    PPMI_vecs = {}\n",
    "    SPPMI_vecs = {}\n",
    "    for word in words:\n",
    "        _vec = get_cooccurprob_vec(word)\n",
    "        _vec[_vec == -np.inf]=0.0\n",
    "        CoProb_vecs[word] = _vec\n",
    "        \n",
    "        _vec = get_pmicds_vec(word)\n",
    "    \n",
    "        #PMI\n",
    "        _pmi_vec = copy.copy(_vec)    \n",
    "        _pmi_vec[_pmi_vec == -np.inf]=0.0\n",
    "        PMI_vecs[word] = _pmi_vec\n",
    "        \n",
    "        #PPMI\n",
    "        _ppmi_vec = copy.copy(_vec)    \n",
    "        _ppmi_vec[_ppmi_vec < 0] = 0\n",
    "        PPMI_vecs[word] = _ppmi_vec\n",
    "    \n",
    "        #SPPMI\n",
    "        _sppmi_vec = copy.copy(_vec)    \n",
    "        _sppmi_vec = _sppmi_vec - np.log(ns)\n",
    "        _sppmi_vec[_sppmi_vec<0] = 0.0\n",
    "        SPPMI_vecs[word] = _sppmi_vec\n",
    "\n",
    "    return CoProb_vecs, PMI_vecs, PPMI_vecs, SPPMI_vecs\n",
    "\n",
    "get_pmibased_vecs(['book'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38065485e+01, -3.07478468e+00, -7.86560477e+00,  3.27757522e-01,\n",
       "       -1.25351224e-01,  5.00331066e-01, -3.28505429e+00, -7.77388278e-01,\n",
       "       -8.87781231e-03, -4.31638237e+00])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_pmisvdbased_vecs(words):\n",
    "    PMISVD_vecs = {}\n",
    "    PPMISVD_vecs = {}\n",
    "    SPPMISVD_vecs = {}\n",
    "    for word in words:\n",
    "        _idx = coomtx_dict.token2id[word]\n",
    "        PMISVD_vecs[word] = pmisvd_matrix[_idx]\n",
    "        PPMISVD_vecs[word] = ppmisvd_matrix[_idx]\n",
    "        SPPMISVD_vecs[word] = sppmisvd_matrix[_idx]\n",
    "\n",
    "    return PMISVD_vecs, PPMISVD_vecs, SPPMISVD_vecs\n",
    "\n",
    "get_pmisvdbased_vecs(['she'])[0]['she'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navid/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'book': 1.0, 'library': 0.9578772703233035},\n",
       " {'book': 1.0, 'library': 0.43006654138569744},\n",
       " {'book': 1.0, 'library': 0.11733015475554986},\n",
       " {'book': 1.0, 'library': 0.04354094496879557})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pmibased_vecs_similarity(word_from, words_to):\n",
    "    CoProb_vecs_from, PMI_vecs_from, PPMI_vecs_from, SPPMI_vecs_from = get_pmibased_vecs([word_from])\n",
    "    CoProb_vecs_to, PMI_vecs_to, PPMI_vecs_to, SPPMI_vecs_to = get_pmibased_vecs(words_to)\n",
    "    \n",
    "    sims_CoProb = {}\n",
    "    sims_PMI = {}\n",
    "    sims_PPMI = {}\n",
    "    sims_SPPMI = {}\n",
    "    for word_to in words_to:\n",
    "        if word_to in coomtx_dict.values():\n",
    "            sims_CoProb[word_to] = Cosine(CoProb_vecs_from[word_from], CoProb_vecs_to[word_to])\n",
    "            sims_PMI[word_to] = Cosine(PMI_vecs_from[word_from], PMI_vecs_to[word_to])\n",
    "            sims_PPMI[word_to] = Cosine(PPMI_vecs_from[word_from], PPMI_vecs_to[word_to])\n",
    "            sims_SPPMI[word_to] = Cosine(SPPMI_vecs_from[word_from], SPPMI_vecs_to[word_to])\n",
    "            \n",
    "    return sims_CoProb, sims_PMI, sims_PPMI, sims_SPPMI\n",
    "\n",
    "get_pmibased_vecs_similarity('book', ['book', 'library'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "genderword_tuples = []\n",
    "\n",
    "with open('resources/wordlist_genderspecific.txt') as fr:\n",
    "    for l in fr:\n",
    "        _tuple=l.strip('\\n').split(',')\n",
    "        if _tuple[0] in we_model.wv.vocab:\n",
    "            _idx = we_model.wv.vocab[_tuple[0]].index\n",
    "            genderword_tuples.append((_tuple[0], _tuple[1], _idx))\n",
    "        else:\n",
    "            print (_tuple[0])\n",
    "print (len([x for x in genderword_tuples if x[1]=='f']))\n",
    "print (len([x for x in genderword_tuples if x[1]=='m']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "coomtx_job_tuples=[]\n",
    "with open('resources/wordlist_occupations.txt') as fr:\n",
    "    for l in fr:\n",
    "        _tuple=l.strip('\\n').split(',')\n",
    "        if _tuple[0] in coomtx_dict.values():\n",
    "            coomtx_job_tuples.append(_tuple)\n",
    "        \n",
    "\n",
    "coomtx_genderword_tuples = []\n",
    "\n",
    "with open('resources/wordlist_genderspecific.txt') as fr:\n",
    "    for l in fr:\n",
    "        _tuple=l.strip('\\n').split(',')\n",
    "        if _tuple[0] in coomtx_dict.values():\n",
    "            _idx = coomtx_dict.token2id[_tuple[0]]\n",
    "            coomtx_genderword_tuples.append((_tuple[0], _tuple[1], _idx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coomtx_fem_exp_feature_vec = np.zeros(len(we_model.wv.vocab))\n",
    "coomtx_masc_exp_feature_vec = np.zeros(len(we_model.wv.vocab))\n",
    "for _tuple in coomtx_genderword_tuples:\n",
    "    if _tuple[1] == 'f':\n",
    "        coomtx_fem_exp_feature_vec[_tuple[2]] = 1\n",
    "    elif _tuple[1] == 'm':\n",
    "        coomtx_masc_exp_feature_vec[_tuple[2]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navid/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "job_CoProb_vecs, job_PMI_vecs, job_PPMI_vecs, job_SPPMI_vecs = get_pmibased_vecs([x[0] for x in coomtx_job_tuples])\n",
    "\n",
    "job_PMISVD_vecs, job_PPMISVD_vecs, job_SPPMISVD_vecs = get_pmisvdbased_vecs([x[0] for x in coomtx_job_tuples])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navid/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "_CoProb_fem_vectors = []\n",
    "_CoProb_masc_vectors = []\n",
    "_PMI_fem_vectors = []\n",
    "_PMI_masc_vectors = []\n",
    "_PPMI_fem_vectors = []\n",
    "_PPMI_masc_vectors = []\n",
    "_SPPMI_fem_vectors = []\n",
    "_SPPMI_masc_vectors = []\n",
    "for _tuple in genderword_tuples:\n",
    "    _CoProb_vecs, _PMI_vecs, _PPMI_vecs, _SPPMI_vecs = get_pmibased_vecs([_tuple[0]])\n",
    "    if _tuple[1] == 'f':\n",
    "        _CoProb_fem_vectors.append(_CoProb_vecs[_tuple[0]])\n",
    "        _PMI_fem_vectors.append(_PMI_vecs[_tuple[0]])\n",
    "        _PPMI_fem_vectors.append(_PPMI_vecs[_tuple[0]])\n",
    "        _SPPMI_fem_vectors.append(_SPPMI_vecs[_tuple[0]])\n",
    "    elif _tuple[1] == 'm':\n",
    "        _CoProb_masc_vectors.append(_CoProb_vecs[_tuple[0]])\n",
    "        _PMI_masc_vectors.append(_PMI_vecs[_tuple[0]])\n",
    "        _PPMI_masc_vectors.append(_PPMI_vecs[_tuple[0]])\n",
    "        _SPPMI_masc_vectors.append(_SPPMI_vecs[_tuple[0]])\n",
    "    \n",
    "fem_CoProb_centroid_vec = np.mean(np.array(_CoProb_fem_vectors), axis=0)\n",
    "masc_CoProb_centroid_vec = np.mean(np.array(_CoProb_masc_vectors), axis=0)\n",
    "fem_PMI_centroid_vec = np.mean(np.array(_PMI_fem_vectors), axis=0)\n",
    "masc_PMI_centroid_vec = np.mean(np.array(_PMI_masc_vectors), axis=0)\n",
    "fem_PPMI_centroid_vec = np.mean(np.array(_PPMI_fem_vectors), axis=0)\n",
    "masc_PPMI_centroid_vec = np.mean(np.array(_PPMI_masc_vectors), axis=0)\n",
    "fem_SPPMI_centroid_vec = np.mean(np.array(_SPPMI_fem_vectors), axis=0)\n",
    "masc_SPPMI_centroid_vec = np.mean(np.array(_SPPMI_masc_vectors), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PMISVD_fem_vectors = []\n",
    "_PMISVD_masc_vectors = []\n",
    "_PPMISVD_fem_vectors = []\n",
    "_PPMISVD_masc_vectors = []\n",
    "_SPPMISVD_fem_vectors = []\n",
    "_SPPMISVD_masc_vectors = []\n",
    "for _tuple in genderword_tuples:\n",
    "    _PMISVD_vecs, _PPMISVD_vecs, _SPPMISVD_vecs = get_pmisvdbased_vecs([_tuple[0]])\n",
    "    if _tuple[1] == 'f':\n",
    "        _PMISVD_fem_vectors.append(_PMISVD_vecs[_tuple[0]])\n",
    "        _PPMISVD_fem_vectors.append(_PPMISVD_vecs[_tuple[0]])\n",
    "        _SPPMISVD_fem_vectors.append(_SPPMISVD_vecs[_tuple[0]])\n",
    "    elif _tuple[1] == 'm':\n",
    "        _PMISVD_masc_vectors.append(_PMISVD_vecs[_tuple[0]])\n",
    "        _PPMISVD_masc_vectors.append(_PPMISVD_vecs[_tuple[0]])\n",
    "        _SPPMISVD_masc_vectors.append(_SPPMISVD_vecs[_tuple[0]])\n",
    "    \n",
    "fem_PMISVD_centroid_vec = np.mean(np.array(_PMISVD_fem_vectors), axis=0)\n",
    "masc_PMISVD_centroid_vec = np.mean(np.array(_PMISVD_masc_vectors), axis=0)\n",
    "fem_PPMISVD_centroid_vec = np.mean(np.array(_PPMISVD_fem_vectors), axis=0)\n",
    "masc_PPMISVD_centroid_vec = np.mean(np.array(_PPMISVD_masc_vectors), axis=0)\n",
    "fem_SPPMISVD_centroid_vec = np.mean(np.array(_SPPMISVD_fem_vectors), axis=0)\n",
    "masc_SPPMISVD_centroid_vec = np.mean(np.array(_SPPMISVD_masc_vectors), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navid/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "#Gender dirction dense\n",
    "\n",
    "_matrix_CoProb = []\n",
    "_matrix_PMI = []\n",
    "_matrix_PPMI = []\n",
    "_matrix_SPPMI = []\n",
    "_matrix_PMISVD = []\n",
    "_matrix_PPMISVD = []\n",
    "_matrix_SPPMISVD = []\n",
    "for a, b in wordpairs_debiasing_direction:\n",
    "    _CoProb_vecs, _PMI_vecs, _PPMI_vecs, _SPPMI_vecs = get_pmibased_vecs([a, b])\n",
    "    _a_CoProb_vec_norm = _CoProb_vecs[a]/np.linalg.norm(_CoProb_vecs[a])\n",
    "    _a_PMI_vec_norm = _PMI_vecs[a]/np.linalg.norm(_PMI_vecs[a])\n",
    "    _a_PPMI_vec_norm = _PPMI_vecs[a]/np.linalg.norm(_PPMI_vecs[a])\n",
    "    _a_SPPMI_vec_norm = _SPPMI_vecs[a]/np.linalg.norm(_SPPMI_vecs[a])\n",
    "    _b_CoProb_vec_norm = _CoProb_vecs[b]/np.linalg.norm(_CoProb_vecs[b])\n",
    "    _b_PMI_vec_norm = _PMI_vecs[b]/np.linalg.norm(_PMI_vecs[b])\n",
    "    _b_PPMI_vec_norm = _PPMI_vecs[b]/np.linalg.norm(_PPMI_vecs[b])\n",
    "    _b_SPPMI_vec_norm = _SPPMI_vecs[b]/np.linalg.norm(_SPPMI_vecs[b])\n",
    "    \n",
    "    _center_CoProb_vec = (_a_CoProb_vec_norm + _b_CoProb_vec_norm)/2\n",
    "    _center_PMI_vec = (_a_PMI_vec_norm + _b_PMI_vec_norm)/2\n",
    "    _center_PPMI_vec = (_a_PPMI_vec_norm + _b_PPMI_vec_norm)/2\n",
    "    _center_SPPMI_vec = (_a_SPPMI_vec_norm + _b_SPPMI_vec_norm)/2\n",
    "    \n",
    "    _matrix_CoProb.append(_a_CoProb_vec_norm - _center_CoProb_vec)\n",
    "    _matrix_PMI.append(_a_PMI_vec_norm - _center_PMI_vec)\n",
    "    _matrix_PPMI.append(_a_PPMI_vec_norm - _center_PPMI_vec)\n",
    "    _matrix_SPPMI.append(_a_SPPMI_vec_norm - _center_SPPMI_vec)\n",
    "    _matrix_CoProb.append(_b_CoProb_vec_norm - _center_CoProb_vec)\n",
    "    _matrix_PMI.append(_b_PMI_vec_norm - _center_PMI_vec)\n",
    "    _matrix_PPMI.append(_b_PPMI_vec_norm - _center_PPMI_vec)\n",
    "    _matrix_SPPMI.append(_b_SPPMI_vec_norm - _center_SPPMI_vec)\n",
    "    \n",
    "    _PMISVD_vecs, _PPMISVD_vecs, _SPPMISVD_vecs = get_pmisvdbased_vecs([a, b])\n",
    "    _a_PMISVD_vec_norm = _PMISVD_vecs[a]/np.linalg.norm(_PMISVD_vecs[a])\n",
    "    _a_PPMISVD_vec_norm = _PPMISVD_vecs[a]/np.linalg.norm(_PPMISVD_vecs[a])\n",
    "    _a_SPPMISVD_vec_norm = _SPPMISVD_vecs[a]/np.linalg.norm(_SPPMISVD_vecs[a])\n",
    "    _b_PMISVD_vec_norm = _PMISVD_vecs[a]/np.linalg.norm(_PMISVD_vecs[b])\n",
    "    _b_PPMISVD_vec_norm = _PPMISVD_vecs[a]/np.linalg.norm(_PPMISVD_vecs[b])\n",
    "    _b_SPPMISVD_vec_norm = _SPPMISVD_vecs[a]/np.linalg.norm(_SPPMISVD_vecs[b])\n",
    "    \n",
    "    _center_PMISVD_vec = (_a_PMISVD_vec_norm + _b_PMISVD_vec_norm)/2\n",
    "    _center_PPMISVD_vec = (_a_PPMISVD_vec_norm + _b_PPMISVD_vec_norm)/2\n",
    "    _center_SPPMISVD_vec = (_a_SPPMISVD_vec_norm + _b_SPPMISVD_vec_norm)/2\n",
    "    _matrix_PMISVD.append(_a_PMISVD_vec_norm - _center_PMISVD_vec)\n",
    "    _matrix_PPMISVD.append(_a_PPMISVD_vec_norm - _center_PPMISVD_vec)\n",
    "    _matrix_SPPMISVD.append(_a_SPPMISVD_vec_norm - _center_SPPMISVD_vec)\n",
    "    _matrix_PMISVD.append(_b_PMISVD_vec_norm - _center_PMISVD_vec)\n",
    "    _matrix_PPMISVD.append(_b_PPMISVD_vec_norm - _center_PPMISVD_vec)\n",
    "    _matrix_SPPMISVD.append(_b_SPPMISVD_vec_norm - _center_SPPMISVD_vec)\n",
    "    \n",
    "_matrix_CoProb = np.array(_matrix_CoProb)\n",
    "_matrix_PMI = np.array(_matrix_PMI)\n",
    "_matrix_PPMI = np.array(_matrix_PPMI)\n",
    "_matrix_SPPMI = np.array(_matrix_SPPMI)\n",
    "_matrix_PMISVD = np.array(_matrix_PMISVD)\n",
    "_matrix_PPMISVD = np.array(_matrix_PPMISVD)\n",
    "_matrix_SPPMISVD = np.array(_matrix_SPPMISVD)\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "gendir_CoProb_vec = pca.fit(_matrix_CoProb).components_[0]\n",
    "gendir_PMI_vec = pca.fit(_matrix_PMI).components_[0]\n",
    "gendir_PPMI_vec = pca.fit(_matrix_PPMI).components_[0]\n",
    "gendir_SPPMI_vec = pca.fit(_matrix_SPPMI).components_[0]\n",
    "gendir_PMISVD_vec = pca.fit(_matrix_PMISVD).components_[0]\n",
    "gendir_PPMISVD_vec = pca.fit(_matrix_PPMISVD).components_[0]\n",
    "gendir_SPPMISVD_vec = pca.fit(_matrix_SPPMISVD).components_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Gender Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_CoProb_1st_mean_bias = []\n",
    "job_PMI_1st_mean_bias = []\n",
    "job_PPMI_1st_mean_bias = []\n",
    "job_SPPMI_1st_mean_bias = []\n",
    "for job_tuple in job_tuples:\n",
    "    _vec = job_CoProb_vecs[job_tuple[0]]\n",
    "    job_CoProb_1st_mean_bias.append((job_tuple[0], np.dot(_vec, coomtx_fem_exp_feature_vec)/np.sum(coomtx_fem_exp_feature_vec) - np.dot(_vec, coomtx_masc_exp_feature_vec)/np.sum(coomtx_masc_exp_feature_vec),\n",
    "                                     np.dot(_vec, coomtx_fem_exp_feature_vec)/np.sum(coomtx_fem_exp_feature_vec),\n",
    "                                     np.dot(_vec, coomtx_masc_exp_feature_vec)/np.sum(coomtx_masc_exp_feature_vec), job_tuple[1]))\n",
    "    _vec = job_PMI_vecs[job_tuple[0]]\n",
    "    job_PMI_1st_mean_bias.append((job_tuple[0], np.dot(_vec, coomtx_fem_exp_feature_vec)/np.sum(coomtx_fem_exp_feature_vec) - np.dot(_vec, coomtx_masc_exp_feature_vec)/np.sum(coomtx_masc_exp_feature_vec), \n",
    "                                  np.dot(_vec, coomtx_fem_exp_feature_vec)/np.sum(coomtx_fem_exp_feature_vec),\n",
    "                                  np.dot(_vec, coomtx_masc_exp_feature_vec)/np.sum(coomtx_masc_exp_feature_vec), job_tuple[1]))\n",
    "    _vec = job_PPMI_vecs[job_tuple[0]]\n",
    "    job_PPMI_1st_mean_bias.append((job_tuple[0], np.dot(_vec, coomtx_fem_exp_feature_vec)/np.sum(coomtx_fem_exp_feature_vec) - np.dot(_vec, coomtx_masc_exp_feature_vec)/np.sum(coomtx_masc_exp_feature_vec),\n",
    "                                   np.dot(_vec, coomtx_fem_exp_feature_vec)/np.sum(coomtx_fem_exp_feature_vec),\n",
    "                                   np.dot(_vec, coomtx_masc_exp_feature_vec)/np.sum(coomtx_masc_exp_feature_vec), job_tuple[1]))\n",
    "    _vec = job_SPPMI_vecs[job_tuple[0]]\n",
    "    job_SPPMI_1st_mean_bias.append((job_tuple[0], np.dot(_vec, coomtx_fem_exp_feature_vec)/np.sum(coomtx_fem_exp_feature_vec) - np.dot(_vec, coomtx_masc_exp_feature_vec)/np.sum(coomtx_masc_exp_feature_vec),\n",
    "                                    np.dot(_vec, coomtx_fem_exp_feature_vec)/np.sum(coomtx_fem_exp_feature_vec),\n",
    "                                    np.dot(_vec, coomtx_masc_exp_feature_vec)/np.sum(coomtx_masc_exp_feature_vec), job_tuple[1]))\n",
    "\n",
    "\n",
    "job_CoProb_1st_mean_bias.sort(key=lambda x: x[1])    \n",
    "job_PMI_1st_mean_bias.sort(key=lambda x: x[1])    \n",
    "job_PPMI_1st_mean_bias.sort(key=lambda x: x[1])    \n",
    "job_SPPMI_1st_mean_bias.sort(key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "                           \n",
    "job_CoProb_2nd_gendir_bias = []\n",
    "job_PMI_2nd_gendir_bias = []\n",
    "job_PPMI_2nd_gendir_bias = []\n",
    "job_SPPMI_2nd_gendir_bias = []\n",
    "for job_tuple in job_tuples:\n",
    "    _vec = job_CoProb_vecs[job_tuple[0]]\n",
    "    job_CoProb_2nd_gendir_bias.append((job_tuple[0], np.dot(_vec, gendir_CoProb_vec), 0.0, 0.0, job_tuple[1]))\n",
    "    \n",
    "    _vec = job_PMI_vecs[job_tuple[0]]\n",
    "    job_PMI_2nd_gendir_bias.append((job_tuple[0], np.dot(_vec, gendir_PMI_vec), 0.0, 0.0, job_tuple[1]))\n",
    "    \n",
    "    _vec = job_PPMI_vecs[job_tuple[0]]\n",
    "    job_PPMI_2nd_gendir_bias.append((job_tuple[0], np.dot(_vec, gendir_PPMI_vec), 0.0, 0.0, job_tuple[1]))\n",
    "    \n",
    "    _vec = job_SPPMI_vecs[job_tuple[0]]\n",
    "    job_SPPMI_2nd_gendir_bias.append((job_tuple[0], np.dot(_vec, gendir_SPPMI_vec), 0.0, 0.0, job_tuple[1]))\n",
    "    \n",
    "\n",
    "job_CoProb_2nd_gendir_bias.sort(key=lambda x: x[1])    \n",
    "job_PMI_2nd_gendir_bias.sort(key=lambda x: x[1])    \n",
    "job_PPMI_2nd_gendir_bias.sort(key=lambda x: x[1])    \n",
    "job_SPPMI_2nd_gendir_bias.sort(key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "                           \n",
    "job_PMISVD_2nd_gendir_bias = []\n",
    "job_PPMISVD_2nd_gendir_bias = []\n",
    "job_SPPMISVD_2nd_gendir_bias = []\n",
    "for job_tuple in job_tuples:\n",
    "    _vec = job_PMISVD_vecs[job_tuple[0]]\n",
    "    job_PMISVD_2nd_gendir_bias.append((job_tuple[0], np.dot(_vec, gendir_PMISVD_vec), 0.0, 0.0, job_tuple[1]))\n",
    "    \n",
    "    _vec = job_PPMISVD_vecs[job_tuple[0]]\n",
    "    job_PPMISVD_2nd_gendir_bias.append((job_tuple[0], np.dot(_vec, gendir_PPMISVD_vec), 0.0, 0.0, job_tuple[1]))\n",
    "    \n",
    "    _vec = job_SPPMISVD_vecs[job_tuple[0]]\n",
    "    job_SPPMISVD_2nd_gendir_bias.append((job_tuple[0], np.dot(_vec, gendir_SPPMISVD_vec), 0.0, 0.0, job_tuple[1]))\n",
    "    \n",
    "\n",
    "job_PMISVD_2nd_gendir_bias.sort(key=lambda x: x[1])    \n",
    "job_PPMISVD_2nd_gendir_bias.sort(key=lambda x: x[1])    \n",
    "job_SPPMISVD_2nd_gendir_bias.sort(key=lambda x: x[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_CoProb_2nd_mean_bias = []\n",
    "job_PMI_2nd_mean_bias = []\n",
    "job_PPMI_2nd_mean_bias = []\n",
    "job_SPPMI_2nd_mean_bias = []\n",
    "for job_tuple in job_tuples:\n",
    "    _vec = job_CoProb_vecs[job_tuple[0]]\n",
    "    job_CoProb_2nd_mean_bias.append((job_tuple[0], meanCosine(_vec, _CoProb_fem_vectors) - meanCosine(_vec, _CoProb_masc_vectors),\n",
    "                                     meanCosine(_vec, _CoProb_masc_vectors), meanCosine(_vec, _CoProb_masc_vectors), job_tuple[1]))\n",
    "    _vec = job_PMI_vecs[job_tuple[0]]\n",
    "    job_PMI_2nd_mean_bias.append((job_tuple[0], meanCosine(_vec, _PMI_fem_vectors) - meanCosine(_vec, _PMI_masc_vectors),\n",
    "                                    meanCosine(_vec, _PMI_masc_vectors), meanCosine(_vec, _PMI_masc_vectors), job_tuple[1]))\n",
    "    _vec = job_PPMI_vecs[job_tuple[0]]\n",
    "    job_PPMI_2nd_mean_bias.append((job_tuple[0], meanCosine(_vec, _PPMI_fem_vectors) - meanCosine(_vec, _PPMI_masc_vectors),\n",
    "                                    meanCosine(_vec, _PPMI_fem_vectors), meanCosine(_vec, _PPMI_masc_vectors), job_tuple[1]))\n",
    "    _vec = job_SPPMI_vecs[job_tuple[0]]\n",
    "    job_SPPMI_2nd_mean_bias.append((job_tuple[0], meanCosine(_vec, _SPPMI_fem_vectors) - meanCosine(_vec, _SPPMI_masc_vectors),\n",
    "                                    meanCosine(_vec, _SPPMI_fem_vectors), meanCosine(_vec, _SPPMI_masc_vectors), job_tuple[1]))\n",
    "    \n",
    "job_CoProb_2nd_mean_bias.sort(key=lambda x: x[1])\n",
    "job_PMI_2nd_mean_bias.sort(key=lambda x: x[1])\n",
    "job_PPMI_2nd_mean_bias.sort(key=lambda x: x[1])\n",
    "job_SPPMI_2nd_mean_bias.sort(key=lambda x: x[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_PMISVD_2nd_mean_bias = []\n",
    "job_PPMISVD_2nd_mean_bias = []\n",
    "job_SPPMISVD_2nd_mean_bias = []\n",
    "for job_tuple in job_tuples:\n",
    "    _vec = job_PMISVD_vecs[job_tuple[0]]\n",
    "    job_PMISVD_2nd_mean_bias.append((job_tuple[0], meanCosine(_vec, _PMISVD_fem_vectors) - meanCosine(_vec, _PMISVD_masc_vectors),\n",
    "                                    meanCosine(_vec, _PMISVD_fem_vectors), meanCosine(_vec, _PMISVD_masc_vectors), job_tuple[1]))\n",
    "    _vec = job_PPMISVD_vecs[job_tuple[0]]\n",
    "    job_PPMISVD_2nd_mean_bias.append((job_tuple[0], meanCosine(_vec, _PPMISVD_fem_vectors) - meanCosine(_vec, _PPMISVD_masc_vectors),\n",
    "                                    meanCosine(_vec, _PPMISVD_fem_vectors), meanCosine(_vec, _PPMISVD_masc_vectors), job_tuple[1]))\n",
    "    _vec = job_SPPMISVD_vecs[job_tuple[0]]\n",
    "    job_SPPMISVD_2nd_mean_bias.append((job_tuple[0], meanCosine(_vec, _SPPMISVD_fem_vectors) - meanCosine(_vec, _SPPMISVD_masc_vectors),\n",
    "                                    meanCosine(_vec, _SPPMISVD_fem_vectors), meanCosine(_vec, _SPPMISVD_masc_vectors), job_tuple[1]))\n",
    "    \n",
    "job_PMISVD_2nd_mean_bias.sort(key=lambda x: x[1])\n",
    "job_PPMISVD_2nd_mean_bias.sort(key=lambda x: x[1])\n",
    "job_SPPMISVD_2nd_mean_bias.sort(key=lambda x: x[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.94418517e-02, 2.54952573e-06, 4.59751157e-08, ...,\n",
       "       3.81460149e-08, 2.76831554e-08, 5.99047020e-08])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masc_CoProb_centroid_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_CoProb_2nd_centroid_bias = []\n",
    "job_PMI_2nd_centroid_bias = []\n",
    "job_PPMI_2nd_centroid_bias = []\n",
    "job_SPPMI_2nd_centroid_bias = []\n",
    "for job_tuple in job_tuples:\n",
    "    _vec = job_CoProb_vecs[job_tuple[0]]\n",
    "    job_CoProb_2nd_centroid_bias.append((job_tuple[0], Cosine(_vec, fem_CoProb_centroid_vec) - Cosine(_vec, masc_CoProb_centroid_vec),\n",
    "                                     Cosine(_vec, fem_CoProb_centroid_vec), Cosine(_vec, masc_CoProb_centroid_vec), job_tuple[1]))\n",
    "    _vec = job_PMI_vecs[job_tuple[0]]\n",
    "    job_PMI_2nd_centroid_bias.append((job_tuple[0], Cosine(_vec, fem_PMI_centroid_vec) - Cosine(_vec, masc_PMI_centroid_vec),\n",
    "                                    Cosine(_vec, fem_PMI_centroid_vec), Cosine(_vec, masc_PMI_centroid_vec), job_tuple[1]))\n",
    "    _vec = job_PPMI_vecs[job_tuple[0]]\n",
    "    job_PPMI_2nd_centroid_bias.append((job_tuple[0], Cosine(_vec, fem_PPMI_centroid_vec) - Cosine(_vec, masc_PPMI_centroid_vec),\n",
    "                                    Cosine(_vec, fem_PPMI_centroid_vec), Cosine(_vec, masc_PPMI_centroid_vec), job_tuple[1]))\n",
    "    _vec = job_SPPMI_vecs[job_tuple[0]]\n",
    "    job_SPPMI_2nd_centroid_bias.append((job_tuple[0], Cosine(_vec, fem_SPPMI_centroid_vec) - Cosine(_vec, masc_SPPMI_centroid_vec),\n",
    "                                    Cosine(_vec, fem_SPPMI_centroid_vec), Cosine(_vec, masc_SPPMI_centroid_vec), job_tuple[1]))\n",
    "    \n",
    "job_CoProb_2nd_centroid_bias.sort(key=lambda x: x[1])\n",
    "job_PMI_2nd_centroid_bias.sort(key=lambda x: x[1])\n",
    "job_PPMI_2nd_centroid_bias.sort(key=lambda x: x[1])\n",
    "job_SPPMI_2nd_centroid_bias.sort(key=lambda x: x[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation to Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "winobias_stats=[]\n",
    "with open('resources/occupations_stats_winobias.txt') as fr:\n",
    "    for l in fr:\n",
    "        _tuple=l.strip('\\n').split(',')\n",
    "        winobias_stats.append((_tuple[0], float(_tuple[1])))\n",
    "print (len(winobias_stats))\n",
    "\n",
    "census_stats=[]\n",
    "with open('resources/occupations_stats_census.txt') as fr:\n",
    "    for l in fr:\n",
    "        _tuple=l.strip('\\n').split(',')\n",
    "        census_stats.append((_tuple[0], float(_tuple[1])))\n",
    "print (len(census_stats))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinoBias\n",
      "----------\n",
      "Spearman\n",
      "   PMISVD_2nd_gendir 0.05\n",
      "  PPMISVD_2nd_gendir 0.05\n",
      " SPPMISVD_2nd_gendir 0.17\n",
      "     PMISVD_2nd_mean 0.41\n",
      "    PPMISVD_2nd_mean 0.41\n",
      "   SPPMISVD_2nd_mean 0.26\n",
      "      PMI_2nd_gendir 0.28\n",
      "        PMI_2nd_mean 0.33\n",
      "    PMI_2nd_centroid 0.14\n",
      "        PMI_1st_mean 0.53\n",
      "     PPMI_2nd_gendir 0.45\n",
      "       PPMI_2nd_mean 0.43\n",
      "   PPMI_2nd_centroid 0.43\n",
      "       PPMI_1st_mean 0.59\n",
      "    SPPMI_2nd_gendir 0.26\n",
      "      SPPMI_2nd_mean 0.32\n",
      "  SPPMI_2nd_centroid 0.39\n",
      "      SPPMI_1st_mean 0.57\n",
      "   CoProb_2nd_gendir 0.22\n",
      "     CoProb_2nd_mean 0.25\n",
      " CoProb_2nd_centroid 0.28\n",
      "     CoProb_1st_mean 0.38\n",
      "\n",
      "Pearson\n",
      "   PMISVD_2nd_gendir 0.07\n",
      "  PPMISVD_2nd_gendir 0.07\n",
      " SPPMISVD_2nd_gendir 0.29\n",
      "     PMISVD_2nd_mean 0.49\n",
      "    PPMISVD_2nd_mean 0.49\n",
      "   SPPMISVD_2nd_mean 0.38\n",
      "      PMI_2nd_gendir 0.07\n",
      "        PMI_2nd_mean 0.24\n",
      "    PMI_2nd_centroid 0.21\n",
      "        PMI_1st_mean 0.51\n",
      "     PPMI_2nd_gendir 0.49\n",
      "       PPMI_2nd_mean 0.46\n",
      "   PPMI_2nd_centroid 0.46\n",
      "       PPMI_1st_mean 0.58\n",
      "    SPPMI_2nd_gendir 0.37\n",
      "      SPPMI_2nd_mean 0.40\n",
      "  SPPMI_2nd_centroid 0.45\n",
      "      SPPMI_1st_mean 0.49\n",
      "   CoProb_2nd_gendir 0.23\n",
      "     CoProb_2nd_mean 0.26\n",
      " CoProb_2nd_centroid 0.28\n",
      "     CoProb_1st_mean 0.42\n",
      "\n",
      "**********\n",
      "U.S. Census Database\n",
      "Spearman\n",
      "   PMISVD_2nd_gendir 0.00\n",
      "  PPMISVD_2nd_gendir 0.00\n",
      " SPPMISVD_2nd_gendir 0.11\n",
      "     PMISVD_2nd_mean 0.49\n",
      "    PPMISVD_2nd_mean 0.49\n",
      "   SPPMISVD_2nd_mean 0.36\n",
      "      PMI_2nd_gendir 0.18\n",
      "        PMI_2nd_mean 0.27\n",
      "    PMI_2nd_centroid 0.35\n",
      "        PMI_1st_mean 0.57\n",
      "     PPMI_2nd_gendir 0.39\n",
      "       PPMI_2nd_mean 0.45\n",
      "   PPMI_2nd_centroid 0.45\n",
      "       PPMI_1st_mean 0.64\n",
      "    SPPMI_2nd_gendir 0.26\n",
      "      SPPMI_2nd_mean 0.44\n",
      "  SPPMI_2nd_centroid 0.45\n",
      "      SPPMI_1st_mean 0.52\n",
      "   CoProb_2nd_gendir 0.29\n",
      "     CoProb_2nd_mean 0.30\n",
      " CoProb_2nd_centroid 0.31\n",
      "     CoProb_1st_mean 0.46\n",
      "\n",
      "Pearson\n",
      "   PMISVD_2nd_gendir 0.00\n",
      "  PPMISVD_2nd_gendir 0.00\n",
      " SPPMISVD_2nd_gendir 0.03\n",
      "     PMISVD_2nd_mean 0.56\n",
      "    PPMISVD_2nd_mean 0.56\n",
      "   SPPMISVD_2nd_mean 0.46\n",
      "      PMI_2nd_gendir 0.02\n",
      "        PMI_2nd_mean 0.19\n",
      "    PMI_2nd_centroid 0.40\n",
      "        PMI_1st_mean 0.62\n",
      "     PPMI_2nd_gendir 0.47\n",
      "       PPMI_2nd_mean 0.52\n",
      "   PPMI_2nd_centroid 0.50\n",
      "       PPMI_1st_mean 0.64\n",
      "    SPPMI_2nd_gendir 0.28\n",
      "      SPPMI_2nd_mean 0.48\n",
      "  SPPMI_2nd_centroid 0.48\n",
      "      SPPMI_1st_mean 0.48\n",
      "   CoProb_2nd_gendir 0.31\n",
      "     CoProb_2nd_mean 0.32\n",
      " CoProb_2nd_centroid 0.33\n",
      "     CoProb_1st_mean 0.53\n",
      "\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import spearmanr\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "def calc_correlations(_stats_jobs, _stats_bias):\n",
    "    job_bias_data = {\n",
    "        'job_PMISVD_2nd_gendir_bias':job_PMISVD_2nd_gendir_bias,\n",
    "        'job_PPMISVD_2nd_gendir_bias':job_PPMISVD_2nd_gendir_bias,\n",
    "        'job_SPPMISVD_2nd_gendir_bias':job_SPPMISVD_2nd_gendir_bias,\n",
    "        'job_PMISVD_2nd_mean_bias':job_PMISVD_2nd_mean_bias,\n",
    "        'job_PPMISVD_2nd_mean_bias':job_PPMISVD_2nd_mean_bias,\n",
    "        'job_SPPMISVD_2nd_mean_bias':job_SPPMISVD_2nd_mean_bias,\n",
    "        \n",
    "        'job_PMI_2nd_gendir_bias':job_PMI_2nd_gendir_bias,\n",
    "        'job_PMI_2nd_mean_bias':job_PMI_2nd_mean_bias,\n",
    "        'job_PMI_2nd_centroid_bias':job_PMI_2nd_centroid_bias,\n",
    "        'job_PMI_1st_mean_bias':job_PMI_1st_mean_bias,\n",
    "        \n",
    "        'job_PPMI_2nd_gendir_bias':job_PPMI_2nd_gendir_bias,\n",
    "        'job_PPMI_2nd_mean_bias':job_PPMI_2nd_mean_bias,\n",
    "        'job_PPMI_2nd_centroid_bias':job_PPMI_2nd_centroid_bias,\n",
    "        'job_PPMI_1st_mean_bias':job_PPMI_1st_mean_bias,\n",
    "        \n",
    "        'job_SPPMI_2nd_gendir_bias':job_SPPMI_2nd_gendir_bias,\n",
    "        'job_SPPMI_2nd_mean_bias':job_SPPMI_2nd_mean_bias,\n",
    "        'job_SPPMI_2nd_centroid_bias':job_SPPMI_2nd_centroid_bias,\n",
    "        'job_SPPMI_1st_mean_bias':job_SPPMI_1st_mean_bias,\n",
    "                     \n",
    "        'job_CoProb_2nd_gendir_bias':job_CoProb_2nd_gendir_bias,\n",
    "        'job_CoProb_2nd_mean_bias':job_CoProb_2nd_mean_bias,\n",
    "        'job_CoProb_2nd_centroid_bias':job_CoProb_2nd_centroid_bias,\n",
    "        'job_CoProb_1st_mean_bias':job_CoProb_1st_mean_bias,\n",
    "        \n",
    "        }\n",
    "    labor_bias = {}\n",
    "    for _data_key in job_bias_data:\n",
    "        labor_bias[_data_key] = []\n",
    "    _idx = 1\n",
    "    for _job in _stats_jobs:\n",
    "        for _data_key in job_bias_data:\n",
    "            labor_bias[_data_key].append([x for x in job_bias_data[_data_key] if x[0]==_job][0][_idx])\n",
    "        \n",
    "    results = {'spearman':{}, 'pearson':{}}\n",
    "    print ('Spearman')\n",
    "    for _data_key in job_bias_data:\n",
    "        _text = _data_key.replace('job_', '').replace('_bias', '')\n",
    "        results['spearman'][_text] = abs(round(spearmanr(labor_bias[_data_key], _stats_bias).correlation, 2))\n",
    "        print (\"%20s %0.2f\" % (_text, results['spearman'][_text]))\n",
    "    print ()\n",
    "    print ('Pearson')\n",
    "    for _data_key in job_bias_data:\n",
    "        _text = _data_key.replace('job_', '').replace('_bias', '')\n",
    "        results['pearson'][_text] = abs(round(pearsonr(labor_bias[_data_key], _stats_bias)[0], 2))\n",
    "        print (\"%20s %0.2f\" % (_text, results['pearson'][_text]))\n",
    "    print ()\n",
    "    \n",
    "    return results\n",
    "    \n",
    "\n",
    "results = {}\n",
    "\n",
    "print (\"WinoBias\")\n",
    "print (\"----------\")\n",
    "results['winobias'] = calc_correlations([x[0] for x in winobias_stats], [x[1] for x in winobias_stats])\n",
    "print (\"**********\")\n",
    "#calc_correlations([x[0] for x in winobias_stats], [np.log((x[1]/100)/(1-(x[1]/100))) for x in winobias_stats])\n",
    "#print (\"**********\")\n",
    "#print ()\n",
    "print (\"U.S. Census Database\")\n",
    "#calc_correlations([x[0] for x in census_stats], [np.log(x[1]/(1-x[1])) for x in census_stats])\n",
    "#print (\"**********\")\n",
    "#print ()\n",
    "results['census'] = calc_correlations([x[0] for x in census_stats], [x[1] for x in census_stats])\n",
    "print (\"**********\")\n",
    "print ()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28 & 0.07 & 0.18 & 0.02\n",
      "0.33 & 0.24 & 0.27 & 0.19\n",
      "0.14 & 0.21 & 0.35 & 0.40\n",
      "0.53 & 0.51 & 0.57 & 0.62\n",
      "0.45 & 0.49 & 0.39 & 0.47\n",
      "0.43 & 0.46 & 0.45 & 0.52\n",
      "0.43 & 0.46 & 0.45 & 0.50\n",
      "0.59 & 0.58 & 0.64 & 0.64\n",
      "0.26 & 0.37 & 0.26 & 0.28\n",
      "0.32 & 0.40 & 0.44 & 0.48\n",
      "0.39 & 0.45 & 0.45 & 0.48\n",
      "0.57 & 0.49 & 0.52 & 0.48\n",
      "0.22 & 0.23 & 0.29 & 0.31\n",
      "0.25 & 0.26 & 0.30 & 0.32\n",
      "0.28 & 0.28 & 0.31 & 0.33\n",
      "0.38 & 0.42 & 0.46 & 0.53\n"
     ]
    }
   ],
   "source": [
    "for x in ['PMI_2nd_gendir','PMI_2nd_mean','PMI_2nd_centroid','PMI_1st_mean',\n",
    "          'PPMI_2nd_gendir','PPMI_2nd_mean','PPMI_2nd_centroid','PPMI_1st_mean',\n",
    "          'SPPMI_2nd_gendir','SPPMI_2nd_mean','SPPMI_2nd_centroid','SPPMI_1st_mean',\n",
    "          'CoProb_2nd_gendir','CoProb_2nd_mean','CoProb_2nd_centroid','CoProb_1st_mean']:\n",
    "    print (\"%0.2f & %0.2f & %0.2f & %0.2f\" % (results['winobias']['spearman'][x],\n",
    "                                             results['winobias']['pearson'][x],\n",
    "                                             results['census']['spearman'][x],\n",
    "                                             results['census']['pearson'][x]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
